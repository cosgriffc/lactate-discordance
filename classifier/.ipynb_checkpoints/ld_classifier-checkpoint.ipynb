{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lactate Discordance Project\n",
    "## Classifier Development\n",
    "### C.V. Cosgriff, MIT Critical Data\n",
    "\n",
    "In this notebook we develop two gradient boosting models to classifiy lactate discordance in the bottom and top quartiles of the APACHE IVa distribution. We create these separetely as the EDA suggested difference in the nature of lactate discordance across groups. We are not applying any missingness procedures because we will use `xgBoost` which is rather robust to missing data and can learn from the missingness. \n",
    "\n",
    "The notebook will be structured as follows:\n",
    "* Data preparation and subcohort creation\n",
    "* Low APACHE IVa cohort classifier\n",
    "    * Development\n",
    "    * Validation\n",
    "* High APACHE IVa cohort classifier\n",
    "    * Development\n",
    "    * Validation\n",
    "\n",
    "As stated above, we'll use the extreme gradient boosting algorithim to fit our models. Hyperparameters will be obtained by a random sampling of the hyperparaemter space per Bergstra et al. who showed this to be superior than grid searching _(Journal of Machine Learning Research 13 (2012) 281-30)_ and estimating the generalization error via 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Envrionment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "cohort = pd.read_csv('./cleaned_cohort.csv')\n",
    "\n",
    "# \"Tableau 20\" colors as RGB.   \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "marker = ['v','o','d','^','s','>','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "# configure matplotlib\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.style.use('classic')\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# configure jupyter for using matplotlib\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Cohort Data for Modeling\n",
    "\n",
    "Because we are using boosted trees, we do not need to scale or normalize. We do however need to convert any categorical variables; this applies to ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra index we don't need from csv\n",
    "cohort = cohort.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# rename ethnicity labels to make them like variable names\n",
    "cohort.loc[cohort.ethnicity == 'African American', 'ethnicity'] = 'african_american'\n",
    "cohort.loc[cohort.ethnicity == 'Native American', 'ethnicity'] = 'native_american'\n",
    "cohort.loc[cohort.ethnicity == 'Other/Unknown', 'ethnicity'] = 'other'\n",
    "cohort.loc[cohort.ethnicity == 'Asian', 'ethnicity'] = 'asian'\n",
    "cohort.loc[cohort.ethnicity == 'Caucasian', 'ethnicity'] = 'caucasian'\n",
    "cohort.loc[cohort.ethnicity == 'Hispanic', 'ethnicity'] = 'hispanic'\n",
    "eth = pd.get_dummies(cohort.ethnicity, prefix = 'eth')\n",
    "eth = eth.drop('eth_caucasian', axis = 1)\n",
    "cohort = pd.concat([cohort, eth], axis = 1)\n",
    "cohort = cohort.drop('ethnicity', axis = 1)\n",
    "\n",
    "# set index to stay ID\n",
    "cohort = cohort.set_index('patientunitstayid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define subcohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_apache_cohort = cohort.loc[cohort.apache_quartile == cohort.apache_quartile.min()]\n",
    "high_apache_cohort = cohort.loc[cohort.apache_quartile == cohort.apache_quartile.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check check the $n$ in each cohort and how many of them had the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low APACHE IVa cohort contains 13204 patients with 38.40% have a discordant lactate level.\n",
      "High APACHE IVa cohort contains 12244 patients with 59.23% have a discordant lactate level.\n"
     ]
    }
   ],
   "source": [
    "print('Low APACHE IVa cohort contains {} patients with {:.2f}% have a discordant lactate level.'\\\n",
    "      .format(low_apache_cohort.shape[0], low_apache_cohort.lactate_discordance.mean()*100))\n",
    "print('High APACHE IVa cohort contains {} patients with {:.2f}% have a discordant lactate level.'\\\n",
    "      .format(high_apache_cohort.shape[0], high_apache_cohort.lactate_discordance.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to modeling the low APACHE IVa cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Low APACHE IVa Classifier\n",
    "\n",
    "We start by dropping lactate and APACHE information from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_apache_cohort = low_apache_cohort.drop(['lactate_min', 'lactate_max', 'apache_quartile', 'apachescore'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we form design and target label matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = low_apache_cohort.lactate_discordance.astype('int32')\n",
    "low_apache_cohort = low_apache_cohort.drop('lactate_discordance', axis = 1)\n",
    "design_matrix = low_apache_cohort.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we form a test/train split. We'll save 25% of the data for final testing of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(design_matrix, target_label, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the parameters for grid search. Some notes on this:\n",
    "* Max depth usually ends up as 6, 7, or 8\n",
    "* The learning rate is generally around 0.05 and shouldn't get above 0.3\n",
    "* Minimum child weight, subsample proportion, and column sample by tree proportion can be used to adjust overfitting\n",
    "* The number of trees (estimators) can be turned up quite high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':['binary:logistic'],\n",
    "          'learning_rate': [0.01, 0.05, 0.1],\n",
    "          'max_depth': [3, 6, 9, 12],\n",
    "          'min_child_weight': [6, 8, 10, 12],\n",
    "          'silent': [True],\n",
    "          'subsample': [0.6, 0.8, 1],\n",
    "          'colsample_bytree': [0.5, 0.75, 1],\n",
    "          'n_estimators': [500, 750, 1000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform a random grid search with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 133.7min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 192.3min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 259.5min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 339.9min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 427.6min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 519.3min\n",
      "[Parallel(n_jobs=4)]: Done 3864 tasks      | elapsed: 632.5min\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "model_xgb = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits = K, shuffle = True, random_state = 42)\n",
    "cv_grid_search = RandomizedSearchCV(model_xgb, param_distributions = params, n_iter = 1000, scoring = 'roc_auc',\\\n",
    "                                    n_jobs = 4, cv = skf.split(X_train, y_train), verbose = 3, random_state = 42 )\n",
    "cv_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then examine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_grid_search.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
